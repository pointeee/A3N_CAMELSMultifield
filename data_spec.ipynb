{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a06e5df5-c543-427d-bfaa-f2a2a3540c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0ada774-3464-4cdb-ab99-c56af2182071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum of log10(M_img) = 15.50328541\n",
      "Minimum of log10(M_img) = 9.66257858\n",
      "Maximum of log10(P_img) = 13.42540932\n",
      "Minimum of log10(P_img) = 0.74502987\n"
     ]
    }
   ],
   "source": [
    "base = \"/home/chenze/data_gpfs02/CAMELS_multifield/raw_data/\"\n",
    "simcode = \"IllustrisTNG\"\n",
    "alias = \"TNG\"\n",
    "\n",
    "# these have length 1000\n",
    "sim_param = np.loadtxt(f'{base}/params_LH_{simcode}.txt', unpack=True)\n",
    "sim_param = np.repeat(sim_param, 15, axis=1).reshape(6, 15000).T\n",
    "\n",
    "M_img = np.load(f'{base}/Maps_Mtot_{simcode}_LH_z=0.00.npy').reshape(15000, 256, 256)\n",
    "M_img = np.log10(M_img)\n",
    "print(f\"Maximum of log10(M_img) = {M_img.max():.8f}\")\n",
    "print(f\"Minimum of log10(M_img) = {M_img.min():.8f}\")\n",
    "M_img = (M_img - M_img.min()) / (M_img.max() - M_img.min())\n",
    "\n",
    "P_img = np.load(f'{base}/Maps_P_{simcode}_LH_z=0.00.npy').reshape(15000, 256, 256)\n",
    "P_img = np.log10(P_img)\n",
    "print(f\"Maximum of log10(P_img) = {P_img.max():.8f}\")\n",
    "print(f\"Minimum of log10(P_img) = {P_img.min():.8f}\")\n",
    "P_img = (P_img - P_img.min()) / (P_img.max() - P_img.min())\n",
    "\n",
    "imgs_all = np.zeros([15000, 2, 256, 256], dtype=np.float32)\n",
    "imgs_all[:,0,:,:] = M_img\n",
    "imgs_all[:,1,:,:] = P_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "491c4bad-d40d-4fe9-baf4-e13d3f76314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/home/chenze/data_gpfs02/CAMELS_multifield/dataset/compiled_img_TNG.npy\", imgs_all)\n",
    "np.save(\"/home/chenze/data_gpfs02/CAMELS_multifield/dataset/compiled_params_TNG.npy\", sim_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08ce951-5caa-4edb-a1e4-c34809cfcca3",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9e104d4-5ed4-4c0b-af6c-adb84be58357",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_min = 9.66257858\n",
    "M_max = 15.50328541\n",
    "P_min = 0.74502987\n",
    "P_max = 13.42540932"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9afc1b90-d9ef-444e-ae6d-e1584d880e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum of log10(M_img) = 15.50328541\n",
      "Minimum of log10(M_img) = 9.66257858\n",
      "Maximum of log10(P_img) = 13.42540932\n",
      "Minimum of log10(P_img) = 0.74502987\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# change these according to your path\n",
    "base = \"/home/chenze/data_gpfs02/CAMELS_multifield/raw_data/\"\n",
    "simcode = \"IllustrisTNG\"\n",
    "alias = \"TNG\"\n",
    "save_path = \"/home/chenze/data_gpfs02/CAMELS_multifield/dataset/\"\n",
    "\n",
    "# the param\n",
    "sim_param = np.loadtxt(f'{base}/params_LH_{simcode}.txt', unpack=True)\n",
    "sim_param = np.repeat(sim_param, 15, axis=1).reshape(6, 15000).T\n",
    "\n",
    "# read & preprocessing img data\n",
    "M_img = np.load(f'{base}/Maps_Mtot_{simcode}_LH_z=0.00.npy').reshape(15000, 256, 256)\n",
    "M_img = np.log10(M_img)\n",
    "print(f\"Maximum of log10(M_img) = {M_img.max():.8f}\") # the normalization should be\n",
    "print(f\"Minimum of log10(M_img) = {M_img.min():.8f}\") # same for two prescriptions!\n",
    "M_img = (M_img - M_min) / (M_max - M_min)\n",
    "\n",
    "P_img = np.load(f'{base}/Maps_P_{simcode}_LH_z=0.00.npy').reshape(15000, 256, 256)\n",
    "P_img = np.log10(P_img)\n",
    "print(f\"Maximum of log10(P_img) = {P_img.max():.8f}\")\n",
    "print(f\"Minimum of log10(P_img) = {P_img.min():.8f}\")\n",
    "P_img = (P_img - P_min) / (P_max - P_min)\n",
    "\n",
    "# combine the data\n",
    "imgs_all = np.zeros([15000, 2, 256, 256], dtype=np.float32)\n",
    "imgs_all[:,0,:,:] = M_img\n",
    "imgs_all[:,1,:,:] = P_img\n",
    "\n",
    "np.save(save_path+f\"compiled_img_{alias}.npy\", imgs_all)\n",
    "np.save(save_path+f\"compiled_params_{alias}.npy\", sim_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e39f4969-eb64-4a81-81c9-6948f1df4e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum of log10(P_img) = 13.43841743\n",
      "Minimum of log10(P_img) = -0.21077976\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# change these according to your path\n",
    "base = \"/home/chenze/data_gpfs02/CAMELS_multifield/raw_data/\"\n",
    "simcode = \"SIMBA\"\n",
    "alias = \"SIMBA\"\n",
    "save_path = \"/home/chenze/data_gpfs02/CAMELS_multifield/dataset/\"\n",
    "\n",
    "# the param\n",
    "sim_param = np.loadtxt(f'{base}/params_LH_{simcode}.txt', unpack=True)\n",
    "sim_param = np.repeat(sim_param, 15, axis=1).reshape(6, 15000).T\n",
    "\n",
    "# read & preprocessing img data\n",
    "M_img = np.load(f'{base}/Maps_Mtot_{simcode}_LH_z=0.00.npy').reshape(15000, 256, 256)\n",
    "M_img = np.log10(M_img)\n",
    "M_img = (M_img - M_img.min()) / (M_img.max() - M_img.min())\n",
    "\n",
    "P_img = np.load(f'{base}/Maps_P_{simcode}_LH_z=0.00.npy').reshape(15000, 256, 256)\n",
    "P_img = np.log10(P_img)\n",
    "print(f\"Maximum of log10(P_img) = {P_img.max():.8f}\")\n",
    "print(f\"Minimum of log10(P_img) = {P_img.min():.8f}\")\n",
    "P_img = (P_img - P_img.min()) / (P_img.max() - P_img.min())\n",
    "\n",
    "# combine the data\n",
    "imgs_all = np.zeros([15000, 2, 256, 256], dtype=np.float32)\n",
    "imgs_all[:,0,:,:] = M_img\n",
    "imgs_all[:,1,:,:] = P_img\n",
    "\n",
    "np.save(save_path+f\"compiled_img_{alias}.npy\", imgs_all)\n",
    "np.save(save_path+f\"compiled_params_{alias}.npy\", sim_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fd6ca55-0911-456a-b5c6-eb1150b537f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(114514)\n",
    "shuffle = np.arange(15000)\n",
    "np.random.shuffle(shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78700359-4bf0-4ba6-8f20-35688e04e1e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m shuffle \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m15000\u001b[39m)\n\u001b[1;32m      3\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(shuffle)\n\u001b[0;32m----> 5\u001b[0m img_list \u001b[38;5;241m=\u001b[39m \u001b[43mimg_list\u001b[49m[shuffle]\n\u001b[1;32m      6\u001b[0m lab_list \u001b[38;5;241m=\u001b[39m lab_list[shuffle]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img_list' is not defined"
     ]
    }
   ],
   "source": [
    "np.random.seed(114514)\n",
    "shuffle = np.arange(15000)\n",
    "np.random.shuffle(shuffle)\n",
    "\n",
    "img_list = img_list[shuffle]\n",
    "lab_list = lab_list[shuffle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ca37681-dc57-48a2-9515-fb3f0f743458",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_list = np.load(\"/home/chenze/data_gpfs02/CAMELS_multifield/dataset/compiled_img_TNG.npy\")\n",
    "lab_list = np.load(\"/home/chenze/data_gpfs02/CAMELS_multifield/dataset/compiled_params_TNG.npy\")\n",
    "\n",
    "np.random.seed(114514)\n",
    "shuffle = np.arange(15000)\n",
    "np.random.shuffle(shuffle)\n",
    "\n",
    "img_list = img_list[shuffle]\n",
    "lab_list = lab_list[shuffle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a02509a-6a1b-474b-a341-807a6f15de69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1226 , 0.6518 , 0.27586, 2.47942, 1.9066 , 1.90924],\n",
       "       [0.4574 , 0.899  , 0.54563, 0.68113, 1.29684, 1.32593],\n",
       "       [0.3966 , 0.6074 , 1.5305 , 0.61132, 0.98146, 1.07848],\n",
       "       ...,\n",
       "       [0.2782 , 0.9062 , 1.95884, 2.27521, 1.74957, 0.62201],\n",
       "       [0.4834 , 0.7282 , 3.22657, 3.78948, 1.09051, 0.51656],\n",
       "       [0.1074 , 0.8474 , 1.03814, 0.45946, 0.7626 , 1.70882]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca58dc9d-709a-4277-9cb6-0cf6fbc2d70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenze/env/miniconda3/envs/torch_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import CosDataset, train_tfm, test_tfm\n",
    "from model import CNN_cosmo\n",
    "\n",
    "rng_seed = 114514\n",
    "training_ratio = 0.7\n",
    "valid_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25cf0e6f-57ba-4bfd-b3e3-bdf8fa02d7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "274e1a17-64ae-4db4-bed7-d8c33139417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_list = np.load(\"/home/chenze/data_gpfs02/CAMELS_multifield/dataset/compiled_img_TNG.npy\")\n",
    "img_list = torch.tensor(img_list)\n",
    "lab_list = np.load(\"/home/chenze/data_gpfs02/CAMELS_multifield/dataset/compiled_params_TNG.npy\")\n",
    "lab_list = torch.tensor(lab_list)\n",
    "\n",
    "\n",
    "np.random.seed(114514)\n",
    "shuffle = np.arange(15000)\n",
    "np.random.shuffle(shuffle)\n",
    "\n",
    "img_list = img_list[shuffle]\n",
    "lab_list = lab_list[shuffle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d08fecd2-2594-4c10-82af-59e49ffb0617",
   "metadata": {},
   "outputs": [],
   "source": [
    "    np.random.seed(rng_seed)\n",
    "    shuffle = np.arange(img_list.shape[0])\n",
    "    np.random.shuffle(shuffle)\n",
    "    \n",
    "    img_list = img_list[shuffle]\n",
    "    lab_list = lab_list[shuffle]\n",
    "    \n",
    "    len_training = int(len(img_list) * training_ratio)\n",
    "    len_valid = int(len(img_list) * training_ratio) + int(len(img_list) * valid_ratio)\n",
    "    \n",
    "    train_set = CosDataset(img_list[:len_training], lab_list[:len_training], tfm=train_tfm)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    valid_set = CosDataset(img_list[len_training:len_valid], lab_list[len_training:len_valid], tfm=test_tfm)\n",
    "    valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    test_set  = CosDataset(img_list[len_valid:], lab_list[len_valid:], tfm=test_tfm)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df581d98-f837-47a9-b7a3-6a1df21ee243",
   "metadata": {},
   "outputs": [],
   "source": [
    "        for step, (batch_data, batch_targ) in enumerate(valid_loader):\n",
    "            batch_data = batch_data.type(torch.FloatTensor).to(device)\n",
    "            batch_targ = batch_targ.type(torch.FloatTensor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8837fb5c-1c3b-4f15-84ad-61b8bf472358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 35, 144,  26,  35,  48,  67, 176,  47, 126, 233],\n",
       "         [195,   4, 107,  27, 248, 207,  20, 253,  46, 134],\n",
       "         [123,  94,  57,  26, 101,  70,  18, 212, 198,  87],\n",
       "         [ 30, 191,  40, 136,  37, 251, 110, 203, 230, 113],\n",
       "         [219, 111, 123,  66,  81, 108, 130, 125,  90, 161],\n",
       "         [216, 132, 201, 131,  94, 217,  50,  64, 181,  27],\n",
       "         [163,  33, 136, 138, 153,  18,  72,   9, 240, 223],\n",
       "         [114, 164, 121, 117,  17,  11, 184,  41,  41,  45],\n",
       "         [ 41,  19, 116, 134,  31, 182,  72, 223, 243, 148],\n",
       "         [182, 109, 194,  44, 209, 225, 183, 245, 217, 113]],\n",
       "\n",
       "        [[106,  57, 123,  17, 222, 228, 110,  40, 125,  58],\n",
       "         [180,  92,  96,  17, 123,  71, 189, 150,  32, 135],\n",
       "         [ 89,  73,  77, 212, 243,  51,  34, 124, 217,   4],\n",
       "         [ 91,  68, 239, 108, 214,  77,  91, 169,  79, 251],\n",
       "         [ 70,  78,  94,  74, 111,  92,  66, 185, 233, 255],\n",
       "         [164, 127, 161, 136, 229, 154, 168, 127, 188,  39],\n",
       "         [225, 230, 165,  19, 134,  59, 230, 124, 117, 207],\n",
       "         [157, 115,  62,  97,  12, 152, 201, 172, 226, 221],\n",
       "         [232, 110,  76,  75, 179,  74, 251, 208, 162, 224],\n",
       "         [198,  30, 114,  23,  75,  79, 173, 199,  33, 137]],\n",
       "\n",
       "        [[ 94, 221, 121,   6,  18,  64, 181,   9, 142, 100],\n",
       "         [132,  29,  54, 123,  73,  76, 246,  93, 251,  75],\n",
       "         [ 42,  22, 169, 200, 129, 113,  31, 129, 145,  29],\n",
       "         [ 44,  35, 163,  18, 121,  51, 167, 116,   0, 187],\n",
       "         [129, 118, 155, 250, 116,  31, 174, 232, 110,  94],\n",
       "         [175, 237, 136,  24,  70, 166, 196, 136, 102, 108],\n",
       "         [ 80,   3, 162, 250, 214, 159,  40, 253, 125, 105],\n",
       "         [219,  32,  60,  43, 238,  56, 184, 209,   5, 221],\n",
       "         [226, 127, 195, 100, 110, 225, 151,  60,  69,   1],\n",
       "         [250,   4, 117, 164,  53,  31, 207,  29, 179, 137]]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0, 256, size=(3, 10, 10), dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01e24f35-7da1-4bc8-944e-2942af81d8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b6f555-74fb-4487-a767-c1ee157911e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
